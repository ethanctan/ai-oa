"""
Database migrations for PostgreSQL - Supabase version
This handles any schema changes that might be needed after initial setup.
"""
import psycopg2
import psycopg2.extras
import os
from dotenv import load_dotenv
import logging

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)

def get_connection():
    """Get a connection to the PostgreSQL database"""
    database_url = os.environ.get('DATABASE_URL')
    if not database_url:
        raise ValueError("DATABASE_URL environment variable not set")
    
    conn = psycopg2.connect(
        database_url,
        cursor_factory=psycopg2.extras.RealDictCursor
    )
    conn.autocommit = False
    return conn

def run_migrations():
    """Run all PostgreSQL migrations in order"""
    logger.info("üîÑ Running PostgreSQL database migrations...")
    
    try:
        conn = get_connection()
        cursor = conn.cursor()
        
        # Check if we need to add any missing columns that might not be in the base schema
        # This is mostly a safety check since the schema should be complete
        
        # Check for missing columns and add them if needed
        ensure_all_columns_exist(cursor, conn)
        
        # Set default values where needed
        set_default_values(cursor, conn)
        
        # Add instance_access_tokens table
        create_instance_access_tokens_table(cursor)
        
        # Add chat_history table
        create_chat_history_table(cursor)

        # Add access_tokens table (invite links)
        create_access_tokens_table(cursor)

        # Add telemetry_events table
        create_telemetry_events_table(cursor)
        
        conn.close()
        logger.info("‚úÖ PostgreSQL migrations completed successfully.")
        
    except Exception as e:
        logger.error(f"‚ùå PostgreSQL migration failed: {str(e)}")
        raise

def ensure_all_columns_exist(cursor, conn):
    """Ensure all expected columns exist in tables"""
    
    # Check companies table
    cursor.execute("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'companies' AND table_schema = 'public'
    """)
    companies_columns = [row['column_name'] for row in cursor.fetchall()]
    
    expected_companies_columns = [
        'auth0_organization_id', 'approved', 'approved_domains'
    ]
    
    for column in expected_companies_columns:
        if column not in companies_columns:
            if column == 'auth0_organization_id':
                cursor.execute("ALTER TABLE companies ADD COLUMN auth0_organization_id TEXT")
                logger.info(f"‚úÖ Added {column} to companies table")
            elif column == 'approved':
                cursor.execute("ALTER TABLE companies ADD COLUMN approved INTEGER DEFAULT 1")
                logger.info(f"‚úÖ Added {column} to companies table")
            elif column == 'approved_domains':
                cursor.execute("ALTER TABLE companies ADD COLUMN approved_domains TEXT")
                logger.info(f"‚úÖ Added {column} to companies table")
    
    # Check tests table
    cursor.execute("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'tests' AND table_schema = 'public'
    """)
    tests_columns = [row['column_name'] for row in cursor.fetchall()]
    
    if 'created_by_user_id' not in tests_columns:
        cursor.execute("ALTER TABLE tests ADD COLUMN created_by_user_id BIGINT REFERENCES users(id)")
        logger.info("‚úÖ Added created_by_user_id to tests table")
    
    # Ensure access_tokens columns exist (expires_at, used)
    cursor.execute(
        """
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'access_tokens' AND table_schema = 'public'
        """
    )
    access_tokens_cols = [row['column_name'] for row in cursor.fetchall()]
    if 'expires_at' not in access_tokens_cols:
        cursor.execute("ALTER TABLE access_tokens ADD COLUMN expires_at TIMESTAMP WITH TIME ZONE NULL")
        logger.info("‚úÖ Added expires_at to access_tokens table")
    if 'used' not in access_tokens_cols:
        cursor.execute("ALTER TABLE access_tokens ADD COLUMN used BOOLEAN DEFAULT FALSE")
        logger.info("‚úÖ Added used to access_tokens table")

    conn.commit()

def set_default_values(cursor, conn):
    """Set default values for any NULL fields that should have defaults"""
    
    # Set default company_id for any records that don't have one
    cursor.execute("UPDATE candidates SET company_id = 1 WHERE company_id IS NULL")
    cursor.execute("UPDATE tests SET company_id = 1 WHERE company_id IS NULL")
    cursor.execute("UPDATE test_instances SET company_id = 1 WHERE company_id IS NULL")
    cursor.execute("UPDATE test_candidates SET company_id = 1 WHERE company_id IS NULL")
    cursor.execute("UPDATE reports SET company_id = 1 WHERE company_id IS NULL")
    cursor.execute("UPDATE access_tokens SET company_id = 1 WHERE company_id IS NULL") 
    
    # Set approved = 1 for companies that don't have it set
    cursor.execute("UPDATE companies SET approved = 1 WHERE approved IS NULL")
    
    conn.commit()
    logger.info("‚úÖ Default values set for all tables")

def test_migration():
    """Test that migrations work properly"""
    try:
        conn = get_connection()
        cursor = conn.cursor()
        
        # Test basic queries
        cursor.execute("SELECT COUNT(*) FROM companies")
        companies = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) FROM candidates")
        candidates = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) FROM tests")
        tests = cursor.fetchone()['count']
        
        conn.close()
        
        return {
            'success': True,
            'message': f'Migration test successful - Companies: {companies}, Candidates: {candidates}, Tests: {tests}'
        }
        
    except Exception as e:
        return {
            'success': False,
            'message': f'Migration test failed: {str(e)}'
        }

# Add instance_access_tokens table
def create_instance_access_tokens_table(cursor):
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS instance_access_tokens (
        id SERIAL PRIMARY KEY,
        token VARCHAR(255) NOT NULL UNIQUE,
        instance_id INTEGER NOT NULL REFERENCES test_instances(id) ON DELETE CASCADE,
        candidate_id INTEGER NOT NULL REFERENCES candidates(id) ON DELETE CASCADE,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(instance_id, candidate_id)
    );
    CREATE INDEX IF NOT EXISTS idx_instance_access_tokens_token ON instance_access_tokens(token);
    CREATE INDEX IF NOT EXISTS idx_instance_access_tokens_instance ON instance_access_tokens(instance_id);
    """)
    logger.info("‚úÖ Added instance_access_tokens table")

# Add chat_history table
def create_chat_history_table(cursor):
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS chat_history (
        id SERIAL PRIMARY KEY,
        instance_id INTEGER NOT NULL REFERENCES test_instances(id) ON DELETE CASCADE,
        user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
        message TEXT NOT NULL,
        role VARCHAR(20) NOT NULL DEFAULT 'user',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );
    CREATE INDEX IF NOT EXISTS idx_chat_history_instance ON chat_history(instance_id);
    CREATE INDEX IF NOT EXISTS idx_chat_history_created_at ON chat_history(created_at);
    """)
    logger.info("‚úÖ Added chat_history table")

# Add access_tokens table (invite tokens)
def create_access_tokens_table(cursor):
    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS access_tokens (
            id SERIAL PRIMARY KEY,
            instance_id INTEGER NOT NULL REFERENCES test_instances(id) ON DELETE CASCADE,
            token VARCHAR(255) NOT NULL UNIQUE,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
            expires_at TIMESTAMP WITH TIME ZONE NULL,
            used BOOLEAN DEFAULT FALSE
        );
        CREATE INDEX IF NOT EXISTS idx_access_tokens_token ON access_tokens(token);
        CREATE INDEX IF NOT EXISTS idx_access_tokens_instance ON access_tokens(instance_id);
        """
    )
    logger.info("‚úÖ Added access_tokens table")

# Add telemetry_events table
def create_telemetry_events_table(cursor):
    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS telemetry_events (
            id SERIAL PRIMARY KEY,
            instance_id INTEGER NOT NULL REFERENCES test_instances(id) ON DELETE CASCADE,
            session_id VARCHAR(128) NOT NULL,
            event_type VARCHAR(64) NOT NULL,
            event_ts_ms BIGINT,
            metadata JSONB DEFAULT '{}'::jsonb,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        );
        CREATE INDEX IF NOT EXISTS idx_telemetry_events_instance ON telemetry_events(instance_id);
        CREATE INDEX IF NOT EXISTS idx_telemetry_events_type ON telemetry_events(event_type);
        CREATE INDEX IF NOT EXISTS idx_telemetry_events_created ON telemetry_events(created_at);
        """
    )
    logger.info("‚úÖ Added telemetry_events table")

# List of all migrations
migrations = [
    # ... existing migrations ...
    create_instance_access_tokens_table,
    create_chat_history_table,
    create_access_tokens_table,
    create_telemetry_events_table,
]

if __name__ == "__main__":
    """Run migrations when script is executed directly"""
    run_migrations() 